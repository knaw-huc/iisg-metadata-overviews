{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a75338e",
   "metadata": {},
   "source": [
    "# Jupyter notebook to query the harvested metadata records from the IISG archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c03f4a",
   "metadata": {},
   "source": [
    "This notebook makes it possible to get overviews and query the metadata records of the International Institute of Social History (IISG) Archives. It uses as source the file \"converted.csv\" obtained via metadata harvesting using the scripts in this repository (https://github.com/lilimelgar/iisg-metadata-overviews).  It contains MARC records from the OAIPMH endpoint. \n",
    "The file contains one record per row, and each marc property (field and subfield) is in a column.\n",
    "\n",
    "Note: the data includes only metadata records at the \"record\" level, not the archival finding aids.\n",
    "\n",
    "Created by Liliana Melgar (April, 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7522543",
   "metadata": {},
   "source": [
    "# A. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cb568",
   "metadata": {},
   "source": [
    "## A1. Import the required python libraries \n",
    "*(nothing to change)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344696ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# to add timestamp to file names\n",
    "import time\n",
    "# import os.path to add paths to files\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a8db4",
   "metadata": {},
   "source": [
    "## A2. Set the path to the csv file \n",
    "*nothing to change if you cloned the repository. If you downloaded the file only (\"archives_as_csv.csv\"), then set here the path to where you have downloaded the file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b5dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to where the transformed csv is located\n",
    "data_directory = os.path.abspath(os.path.join('..', 'data'))\n",
    "data_converted = os.path.join(data_directory, 'converted') #path to the repository folder where the csv file is located, if you have not cloned the repository, change the path here\n",
    "data_downloads = os.path.join(data_directory, 'downloads') #path to the folder where the reports will be downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79da8e",
   "metadata": {},
   "source": [
    "## A3. Read the csv file as a pandas dataframe\n",
    "*nothing to change here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde84496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv as dataframe\n",
    "archive_df_v0 = pd.read_csv(f'{data_converted}/archives_as_csv.gzip', sep=\"\\t\", compression='gzip', low_memory=False)\n",
    "# low_memory=False was set after this warning message: \"/var/folders/3y/xbjxw0b94jxg6x2bcbyjsmmcgvnf7q/T/ipykernel_987/2912965462.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a194d",
   "metadata": {},
   "source": [
    "# B. First overview and data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117ec8a",
   "metadata": {},
   "source": [
    "## B1. First overview: all fields and data types\n",
    "Execute the cell and view the general information of the data, which includes the Columns (marc properties with subfields), the Non-Null Count (i.e., how many cells have values; for example: if a cell says \"1 non-null\" it means that only one row has a value); and the Data type (object (i.e., a string or a combination of data types), a float or an integer).\n",
    "- Keep in mind that the MARC labels have 3 characters, and that the fourth character can be an indicator or a subfield. For example: 1000 is Marc label 100 with indicator 0. And 100a is Marc label 100 with subfield a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143e8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5423 entries, 0 to 5422\n",
      "Data columns (total 69 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   001     5423 non-null   object \n",
      " 1   003     5423 non-null   object \n",
      " 2   008     5423 non-null   object \n",
      " 3   040a    5423 non-null   object \n",
      " 4   040b    5423 non-null   object \n",
      " 5   040c    5423 non-null   object \n",
      " 6   040e    5415 non-null   object \n",
      " 7   041a    5423 non-null   object \n",
      " 8   1000    4 non-null      float64\n",
      " 9   100a    2377 non-null   object \n",
      " 10  100c    1 non-null      object \n",
      " 11  100d    2 non-null      object \n",
      " 12  100e    2377 non-null   object \n",
      " 13  100q    1 non-null      object \n",
      " 14  1100    1 non-null      float64\n",
      " 15  110a    2255 non-null   object \n",
      " 16  110b    478 non-null    object \n",
      " 17  110e    2255 non-null   object \n",
      " 18  245a    5423 non-null   object \n",
      " 19  245f    5416 non-null   object \n",
      " 20  245g    1367 non-null   object \n",
      " 21  300a    5423 non-null   object \n",
      " 22  300f    164 non-null    object \n",
      " 23  351a    1862 non-null   object \n",
      " 24  500a    272 non-null    object \n",
      " 25  506a    5418 non-null   object \n",
      " 26  520a    5291 non-null   object \n",
      " 27  524a    5404 non-null   object \n",
      " 28  530a    304 non-null    object \n",
      " 29  535a    239 non-null    object \n",
      " 30  540a    737 non-null    object \n",
      " 31  541a    4172 non-null   object \n",
      " 32  544d    532 non-null    object \n",
      " 33  545a    4374 non-null   object \n",
      " 34  546a    5351 non-null   object \n",
      " 35  555a    329 non-null    object \n",
      " 36  561a    759 non-null    object \n",
      " 37  583a    2533 non-null   object \n",
      " 38  6000    38 non-null     object \n",
      " 39  6002    1561 non-null   object \n",
      " 40  6004    1550 non-null   object \n",
      " 41  600a    1567 non-null   object \n",
      " 42  600q    1 non-null      object \n",
      " 43  6102    2091 non-null   object \n",
      " 44  6104    2069 non-null   object \n",
      " 45  610a    2094 non-null   object \n",
      " 46  610b    8 non-null      object \n",
      " 47  610e    1 non-null      object \n",
      " 48  6502    5381 non-null   object \n",
      " 49  650a    5381 non-null   object \n",
      " 50  6512    5421 non-null   object \n",
      " 51  651a    5421 non-null   object \n",
      " 52  6552    5349 non-null   object \n",
      " 53  655a    5349 non-null   object \n",
      " 54  7000    2 non-null      float64\n",
      " 55  7004    3 non-null      object \n",
      " 56  700a    238 non-null    object \n",
      " 57  700e    236 non-null    object \n",
      " 58  7104    1 non-null      object \n",
      " 59  710a    381 non-null    object \n",
      " 60  710b    118 non-null    object \n",
      " 61  710e    380 non-null    object \n",
      " 62  852a    5423 non-null   object \n",
      " 63  852b    5423 non-null   object \n",
      " 64  852j    5423 non-null   object \n",
      " 65  856q    5423 non-null   object \n",
      " 66  856u    5423 non-null   object \n",
      " 67  902a    5423 non-null   object \n",
      " 68  leader  5423 non-null   object \n",
      "dtypes: float64(3), object(66)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "archive_df_v0.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5f9b0",
   "metadata": {},
   "source": [
    "## B2. Optional (documentation)\n",
    "Ideally, each field above would have a definition explaining what it means and what kind of values does it contain (in relation to the conventions for creating IISG metadata). That documentation can exist somewhere else (e.g., on Confluence), but this could be a place to start updating or writing those definitions since here one can see the data that they contain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71f685",
   "metadata": {},
   "source": [
    "- 001 : record Id\n",
    "- 003\n",
    "- 008\n",
    "- 040a\n",
    "- 040b\n",
    "- 040c\n",
    "- 040e\n",
    "- 041a\n",
    "- 1000\n",
    "- 100a\n",
    "- 100c\n",
    "- 100d\n",
    "- 100e\n",
    "- 100q\n",
    "- 1100\n",
    "- 110a\n",
    "- 110b\n",
    "- 110e\n",
    "- 245a\n",
    "- 245f\n",
    "- 245g\n",
    "- 300a\n",
    "- 300f\n",
    "- 351a\n",
    "- 500a\n",
    "- 506a\n",
    "- 520a\n",
    "- 524a\n",
    "- 530a\n",
    "- 535a\n",
    "- 540a\n",
    "- 541a\n",
    "- 544d\n",
    "- 545a\n",
    "- 546a\n",
    "- 555a\n",
    "- 561a\n",
    "- 583a\n",
    "- 6000\n",
    "- 6002\n",
    "- 6004\n",
    "- 600a\n",
    "- 600q\n",
    "- 6102\n",
    "- 6104\n",
    "- 610a\n",
    "- 610b\n",
    "- 610e\n",
    "- 6502\n",
    "- 650a\n",
    "- 6512\n",
    "- 651a\n",
    "- 6552\n",
    "- 655a\n",
    "- 7000\n",
    "- 7004\n",
    "- 700a\n",
    "- 700e\n",
    "- 7104\n",
    "- 710a\n",
    "- 710b\n",
    "- 710e\n",
    "- 852a\n",
    "- 852b\n",
    "- 852j\n",
    "- 856q\n",
    "- 856u\n",
    "- 902a\n",
    "- leader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a169b5e",
   "metadata": {},
   "source": [
    "## B3. Prepare the data for search\n",
    "Because we know that the data doesn't have proper numerical values to be computed, we rather convert all values to strings in order to facilitate querying. This also includes filling in empty values with a standard string: \"null\"\n",
    "*(nothing to change here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes and fill in empty values\n",
    "df_columns = archive_df_v0.columns\n",
    "for column in df_columns:\n",
    "    dataType = archive_df_v0.dtypes[column]\n",
    "    if dataType == np.float64:\n",
    "        archive_df_v0[column] = archive_df_v0[column].fillna('null')\n",
    "        archive_df_v0[column] = archive_df_v0[column].astype(str)\n",
    "    if dataType == object:\n",
    "        archive_df_v0[column] = archive_df_v0[column].fillna('null')\n",
    "        archive_df_v0[column] = archive_df_v0[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy\n",
    "archive_df = archive_df_v0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again the general information of the data after having filled in the emtpy values and converted the data types\n",
    "archive_df.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f8e0b",
   "metadata": {},
   "source": [
    "# C. Get a glimpse of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a598cdf",
   "metadata": {},
   "source": [
    "## C1. First rows\n",
    "Here you can see a sample of the records, one per line. You can change the value \"10\" to any other desired size for your sample, preferably not too big. You can also use \"tail\" instead of \"head\" to see the records in the last rows.\n",
    "- Keep in mind to scroll horizontally and vertically to see the entire record.\n",
    "- NaN means that the cell is empty.\n",
    "- Arbitrarily, some cells above, we decided that the omega \"Ω\" would be the separator for multi-value cells. For example, this archive: ARCH00002 contains two persons as topics in field 600a, which show here separated by \"Ω\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638495f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archive_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe52e6",
   "metadata": {},
   "source": [
    "## C2. Size (shape) of the data\n",
    "Here you can see how many rows (first value) and how many columns (second value) are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821f442",
   "metadata": {},
   "source": [
    "## C3. Unique values\n",
    "Here you can see a general description of the data, including how many unique values are per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the dataframe\n",
    "archive_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a3cbd",
   "metadata": {},
   "source": [
    "# D. Check the values in one column (marc property)\n",
    "At this point you may be curious to know which values are in one column. For example, 100e has only 3 unique values, which are those?\n",
    "- You can change the field inside the quotation marcs for any other field of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df['100e'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de1c14",
   "metadata": {},
   "source": [
    "## D1. Create a subset with certain column(s)/field(s)\n",
    "At this point you may have thought that you could perhaps correct some of the records which contain an inconsistent value. For example, in the first version of this data, if you queried above for \"archive_df['100e'].unique()\" you may have obtained these values: ['creator.', 'null', 'creator']. You may decide that you want to change \"creator.\" into \"creator\". But for this, you need the TCN (record Id) numbers. The command below facilitates creating a subset with the TCN and the field of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset with record Id and record of interest, here enter the name of the field(s) that you are interested in separated by commas, each field has to be within single quotation marks, e.g., archive_df[['001','100e', '110e']]\n",
    "field_subset_df = archive_df[['001','100e']]\n",
    "field_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of unique values in your subset\n",
    "field_subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to dowload the table above to an excel file for further inspection:\n",
    "\n",
    "# choose any name for your file, the file will go to the ../data/downloads folder.\n",
    "name_file = 'archives_relator_field_100e'\n",
    "\n",
    "field_subset_df.to_excel(f'{data_downloads}/{name_file}.xlsx')\n",
    "\n",
    "## or download to csv\n",
    "# field_subset_df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e9ed3",
   "metadata": {},
   "source": [
    "## D2. Create a subset of records with a certain value in a given column\n",
    "You may also want to create a list of the records with a certain value in a given column, for example, for field 100e you got these unique values: ['creator.', 'null', 'creator']. You may want to get only the list of records that have \"creator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a string value exists in a column (the string is exactly the same)\n",
    "query_value_exact = field_subset_df[field_subset_df['100e'] == 'creator.']\n",
    "query_value_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a string value exists in a column (the string is approximately the same)\n",
    "# you may want to find the records that have either \"creator.\" (with dot) or \"creator\" without dot, but not the null values\n",
    "# here it's possible to use regular expressions\n",
    "\n",
    "query_value_aprox = field_subset_df[field_subset_df['100e'].str.contains(\"creator\", case=False, regex=True)]\n",
    "query_value_aprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some idea of how many rows are in this set\n",
    "query_value_aprox.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of unique values in your subset\n",
    "query_value_aprox.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to dowload the table above to an excel file for further inspection:\n",
    "\n",
    "# choose any name for your file, the file will go to the ../data/downloads folder.\n",
    "name_file = 'archives_relator_field_100e_creator'\n",
    "\n",
    "query_value_aprox.to_excel(f'{data_downloads}/{name_file}.xlsx')\n",
    "\n",
    "## or download to csv\n",
    "# query_value_aprox.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c72f9d",
   "metadata": {},
   "source": [
    "# E. Create subsets using inverse query\n",
    "You may need to create a report with all the records that do not contain a certain value. For example, because we used \"null\" to fill in all empty values, one could create a list with all the records that have a value in a certain column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a slice with the records that have non-null values in the column of interest\n",
    "# Note: if you want to query the subset instead of the whole data, then replace \"archive_df\" with \"field_subset_df\" and run the cell again\n",
    "\n",
    "query_inverse = archive_df[~archive_df['100e'].str.contains(\"null\", case=False, regex=True)]\n",
    "\n",
    "query_inverse.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2042fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some info about the subset you got as a result of the query:\n",
    "query_inverse.info(verbose=True, show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to dowload the table above to an excel file for further inspection:\n",
    "\n",
    "# choose any name for your file, the file will go to the ../data/downloads folder.\n",
    "name_file = 'archives_relator_field_100e_notEmpty'\n",
    "\n",
    "query_inverse.to_excel(f'{data_downloads}/{name_file}.xlsx')\n",
    "\n",
    "## or download to csv\n",
    "# query_inverse.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d2b27",
   "metadata": {},
   "source": [
    "# F. Query for a specific record\n",
    "You may want to see the details of a specific record, this can be done in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb773390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. by using the index position. Example: This archive: 10622/ARCH00001 has index position 0. \n",
    "# This position can be seen in the left corner of the entire table (cell above in Section5: archive_df.head(10))\n",
    "# We will query it using the entire version of the data, not the subset\n",
    "\n",
    "# show record vertically using index position\n",
    "query_recordIndex = archive_df.iloc[0]\n",
    "query_recordIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. By using the record Id using the Marc field 001\n",
    "query_recordId = archive_df[archive_df['001'] == '10622/ARCH00001']\n",
    "query_recordId"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
