{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a75338e",
   "metadata": {},
   "source": [
    "# Jupyter notebook to query the harvested metadata records from the IISG bibliographic materials (biblio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c03f4a",
   "metadata": {},
   "source": [
    "This notebook makes it possible to get overviews and query the metadata records of the International Institute of Social History (IISG) Bibliographic materials (\"Biblio\"). It uses as source the file \"converted.csv\" obtained via metadata harvesting using the scripts in this repository (https://github.com/lilimelgar/iisg-metadata-overviews).  It contains MARC records from the OAIPMH endpoint. \n",
    "The file contains one record per row, and each marc property (field and subfield) is in a column.\n",
    "\n",
    "Note: the data includes only metadata records at the \"item\" level.\n",
    "\n",
    "Created by Liliana Melgar (April, 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7522543",
   "metadata": {},
   "source": [
    "# A. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cb568",
   "metadata": {},
   "source": [
    "## A1. Import the required python libraries \n",
    "*(nothing to change)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344696ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# to add timestamp to file names\n",
    "import time\n",
    "# import os.path to add paths to files\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a8db4",
   "metadata": {},
   "source": [
    "## A2. Set the path to the csv file \n",
    "*nothing to change if you cloned the repository. If you downloaded the file only (\"biblio_as_csv.gzip\"), then set here the path to where you have downloaded the file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b5dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to where the transformed csv is located\n",
    "data_directory = os.path.abspath(os.path.join('..', 'data'))\n",
    "data_converted = os.path.join(data_directory, 'converted') #path to the repository folder where the csv file is located, if you have not cloned the repository, change the path here\n",
    "data_downloads = os.path.join(data_directory, 'downloads') #path to the folder where the reports will be downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79da8e",
   "metadata": {},
   "source": [
    "## A3. Read the csv file as a pandas dataframe\n",
    "*nothing to change here, just be patient, IT TAKES LONG TO LOAD (around )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde84496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv as dataframe\n",
    "biblio_df_v0 = pd.read_csv(f'{data_converted}/biblio_as_csv.gzip', sep=\"\\t\", compression='gzip', low_memory=False)\n",
    "# low_memory=False was set after this warning message: \"/var/folders/3y/xbjxw0b94jxg6x2bcbyjsmmcgvnf7q/T/ipykernel_987/2912965462.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a194d",
   "metadata": {},
   "source": [
    "# B. First overview and data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117ec8a",
   "metadata": {},
   "source": [
    "## B1. First overview: all fields and data types\n",
    "Execute the cell and view the general information of the data, which includes the Columns (marc properties with subfields), the Non-Null Count (i.e., how many cells have values; for example: if a cell says \"1 non-null\" it means that only one row has a value); and the Data type (object (i.e., a string or a combination of data types), a float or an integer).\n",
    "- Keep in mind that the MARC labels have 3 characters, and that the fourth character can be an indicator or a subfield. For example: 1000 is Marc label 100 with indicator 0. And 100a is Marc label 100 with subfield a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio_df_v0.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5f9b0",
   "metadata": {},
   "source": [
    "## B2. Optional (documentation)\n",
    "Ideally, each field above would have a definition explaining what it means and what kind of values does it contain (in relation to the conventions for creating IISG metadata). That documentation can exist somewhere else (e.g., on Confluence), but this could be a place to start updating or writing those definitions since here one can see the data that they contain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71f685",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a169b5e",
   "metadata": {},
   "source": [
    "## B3. Prepare the data for search\n",
    "Because we know that the data doesn't have proper numerical values to be computed, we rather convert all values to strings in order to facilitate querying. This also includes filling in empty values with a standard string: \"null\"\n",
    "*(nothing to change here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes and fill in empty values\n",
    "df_columns = biblio_df_v0.columns\n",
    "for column in df_columns:\n",
    "    dataType = biblio_df_v0.dtypes[column]\n",
    "    if dataType == np.float64:\n",
    "        biblio_df_v0[column] = biblio_df_v0[column].fillna('null')\n",
    "        biblio_df_v0[column] = biblio_df_v0[column].astype(str)\n",
    "    if dataType == np.int_:\n",
    "        biblio_df_v0[column] = biblio_df_v0[column].fillna('null')\n",
    "        biblio_df_v0[column] = biblio_df_v0[column].astype(str)\n",
    "    if dataType == object:\n",
    "        biblio_df_v0[column] = biblio_df_v0[column].fillna('null')\n",
    "        biblio_df_v0[column] = biblio_df_v0[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy\n",
    "biblio_df = biblio_df_v0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again the general information of the data after having filled in the emtpy values and converted the data types\n",
    "biblio_df.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f8e0b",
   "metadata": {},
   "source": [
    "# C. Get a glimpse of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a598cdf",
   "metadata": {},
   "source": [
    "## C1. First rows\n",
    "Here you can see a sample of the records, one per line. You can change the value \"10\" to any other desired size for your sample, preferably not too big. You can also use \"tail\" instead of \"head\" to see the records in the last rows.\n",
    "- Keep in mind to scroll horizontally and vertically to see the entire record.\n",
    "- NaN means that the cell is empty.\n",
    "- Arbitrarily, some cells above, we decided that the omega \"â„¦\" would be the separator for multi-value cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638495f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "biblio_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe52e6",
   "metadata": {},
   "source": [
    "## C2. Size (shape) of the data\n",
    "Here you can see how many rows (first value) and how many columns (second value) are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821f442",
   "metadata": {},
   "source": [
    "## C3. Unique values\n",
    "Here you can see a general description of the data, including how many unique values are per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the dataframe\n",
    "biblio_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a3cbd",
   "metadata": {},
   "source": [
    "# D. Check the values in one column (marc property)\n",
    "At this point you may be curious to know which values are in one column. For example, 100e has only 3 unique values, which are those?\n",
    "- You can change the field inside the quotation marcs for any other field of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio_df['100a'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de1c14",
   "metadata": {},
   "source": [
    "## D1. Create a subset with certain column(s)/field(s)\n",
    "At this point you may have thought that you could perhaps correct some of the records which contain an inconsistent value. For example, in the first version of this data, if you queried above for \"biblio_df['100e'].unique()\" you may have obtained certain values. You may decide that you want to change one or some of them into another value. But for this, you need the TCN (record Id) numbers. The command below facilitates creating a subset with the TCN and the field of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subset with record Id and record of interest, here enter the name of the field(s) that you are interested in separated by commas, each field has to be within single quotation marks, e.g., biblio_df[['001','100e', '110e']]\n",
    "field_subset_df = biblio_df[['001','100a']]\n",
    "field_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of unique values in your subset\n",
    "field_subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to dowload the table above to an excel file for further inspection:\n",
    "\n",
    "# choose any name for your file, the file will go to the ../data/downloads folder.\n",
    "name_file = 'biblio_author_person_field_100a'\n",
    "\n",
    "field_subset_df.to_excel(f'{data_downloads}/{name_file}.xlsx')\n",
    "\n",
    "## or download to csv\n",
    "# field_subset_df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e9ed3",
   "metadata": {},
   "source": [
    "## D2. Create a subset of records with a certain value in a given column\n",
    "You may also want to create a list of the records with a certain value in a given column, for example, for field 100e you got these unique values: ['creator.', 'null', 'creator']. You may want to get only the list of records that have \"creator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a string value exists in a column (the string is exactly the same)\n",
    "query_value_exact = field_subset_df[field_subset_df['100a'] == 'Hajnal, Henri.']\n",
    "query_value_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a string value exists in a column (the string is approximately the same)\n",
    "# you may want to find the records that have either \"creator.\" (with dot) or \"creator\" without dot, but not the null values\n",
    "# here it's possible to use regular expressions\n",
    "\n",
    "query_value_aprox = field_subset_df[field_subset_df['100a'].str.contains(\"henri\", case=False, regex=True)]\n",
    "query_value_aprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some idea of how many rows are in this set\n",
    "query_value_aprox.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of unique values in your subset\n",
    "query_value_aprox.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to dowload the table above to an excel file for further inspection:\n",
    "\n",
    "# choose any name for your file, the file will go to the ../data/downloads folder.\n",
    "name_file = 'biblio_author_person_field_100a_henri'\n",
    "\n",
    "query_value_aprox.to_excel(f'{data_downloads}/{name_file}.xlsx')\n",
    "\n",
    "## or download to csv\n",
    "# query_value_aprox.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c72f9d",
   "metadata": {},
   "source": [
    "# E. Create subsets using inverse query\n",
    "You may need to create a report with all the records that do not contain a certain value. For example, because we used \"null\" to fill in all empty values, one could create a list with all the records that have a value in a certain column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a slice with the records that have non-null values in the column of interest\n",
    "# Note: if you want to query the subset instead of the whole data, then replace \"biblio_df\" with \"field_subset_df\" and run the cell again\n",
    "\n",
    "query_inverse = biblio_df[~biblio_df['100a'].str.contains(\"null\", case=False, regex=True)]\n",
    "\n",
    "query_inverse.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2042fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some info about the subset you got as a result of the query:\n",
    "query_inverse.info(verbose=True, show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to dowload the table above to an excel file for further inspection:\n",
    "\n",
    "# choose any name for your file, the file will go to the ../data/downloads folder.\n",
    "name_file = 'biblio_author_person_field_100a_notEmpty'\n",
    "\n",
    "query_inverse.to_excel(f'{data_downloads}/{name_file}.xlsx')\n",
    "\n",
    "## or download to csv\n",
    "# query_inverse.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d2b27",
   "metadata": {},
   "source": [
    "# F. Query for a specific record\n",
    "You may want to see the details of a specific record, this can be done in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb773390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. by using the index position. Example: This item: ToDo has index position 0. \n",
    "# This position can be seen in the left corner of the entire table (cell above in Section5: biblio_df.head(10))\n",
    "# We will query it using the entire version of the data, not the subset\n",
    "\n",
    "# show record vertically using index position\n",
    "query_recordIndex = biblio_df.iloc[0]\n",
    "query_recordIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. By using the record Id using the Marc field 001\n",
    "query_recordId = biblio_df[biblio_df['001'] == '8']\n",
    "query_recordId"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
